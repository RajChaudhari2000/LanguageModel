{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers\n",
        "# !pip install torch\n",
        "# !pip install SPARQLWrapper\n",
        "# !pip install spacy\n",
        "# !pip install PyQt6\n",
        "# !pip install tqdm"
      ],
      "metadata": {
        "id": "bVtxLjQxj1uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "from PyQt6.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QLineEdit, QPushButton, QTextEdit\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "vUte21k6jpYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from DBpedia\n",
        "dataset = load_dataset(\"dbpedia_14\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsRIRdLsjsnw",
        "outputId": "3e6fdd5b-1c37-4989-98f7-2a78ac0480cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['label', 'title', 'content'],\n",
            "        num_rows: 560000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['label', 'title', 'content'],\n",
            "        num_rows: 70000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "1pHoMnMbrY5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to preprocess text data\n",
        "def preprocess_data(texts, labels, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        input_ids.append(encoded[\"input_ids\"].squeeze(0))\n",
        "        attention_masks.append(encoded[\"attention_mask\"].squeeze(0))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.stack(input_ids)\n",
        "    attention_masks = torch.stack(attention_masks)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return input_ids, attention_masks, labels"
      ],
      "metadata": {
        "id": "TZnsoXdusdeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Transformer-based Language Model\n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, model_name, output_dim):\n",
        "        super(CustomTransformerModel, self).__init__()\n",
        "        self.transformer = AutoModel.from_pretrained(model_name)\n",
        "        self.fc = nn.Linear(self.transformer.config.hidden_size, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.transformer(input_ids, attention_mask=attention_mask)\n",
        "        output = self.fc(outputs.last_hidden_state[:, -1, :])\n",
        "        return self.softmax(output)"
      ],
      "metadata": {
        "id": "nnar-TDZoXD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "model_name = \"bert-base-uncased\"\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = CustomTransformerModel(model_name, vocab_size)\n",
        "\n",
        "# Training Setup\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, data, masks, labels, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch, mask, label in zip(data, masks, labels):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=batch, attention_mask=mask)\n",
        "            loss = criterion(outputs, label)  # Ensure labels match the output shape\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "mW7k4LzIobZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load NLP Model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def query_dbpedia(entity):\n",
        "    sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
        "    sparql.setQuery(f\"\"\"\n",
        "    SELECT ?subject ?predicate ?object WHERE {{\n",
        "      ?subject ?predicate ?object .\n",
        "      FILTER (regex(str(?subject), \"{entity}\", \"i\"))\n",
        "    }} LIMIT 10\n",
        "    \"\"\")\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "    triplets = [(res[\"subject\"][\"value\"], res[\"predicate\"][\"value\"], res[\"object\"][\"value\"]) for res in results[\"results\"][\"bindings\"]]\n",
        "    return triplets\n",
        "\n",
        "def triplet_to_natural(triplets):\n",
        "    return \" \".join([f\"{s.replace('_', ' ')} {p.replace('_', ' ')} {o.replace('_', ' ')}.\" for s, p, o in triplets])"
      ],
      "metadata": {
        "id": "XT5ILQ8EHTfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akcGjRO3jeJ4"
      },
      "outputs": [],
      "source": [
        "class ChatBot(QWidget):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.init_ui()\n",
        "\n",
        "    def init_ui(self):\n",
        "        self.setWindowTitle(\"DBpedia Chatbot\")\n",
        "        self.setGeometry(200, 200, 600, 400)\n",
        "        layout = QVBoxLayout()\n",
        "        self.chat_history = QTextEdit()\n",
        "        self.chat_history.setReadOnly(True)\n",
        "        self.input = QLineEdit()\n",
        "        self.input.setPlaceholderText(\"Ask me anything...\")\n",
        "        self.input.returnPressed.connect(self.handle_query)\n",
        "        self.send_button = QPushButton(\"Send\")\n",
        "        self.send_button.clicked.connect(self.handle_query)\n",
        "        layout.addWidget(QLabel(\"DBpedia Chatbot\"))\n",
        "        layout.addWidget(self.chat_history)\n",
        "        layout.addWidget(self.input)\n",
        "        layout.addWidget(self.send_button)\n",
        "        self.setLayout(layout)\n",
        "\n",
        "    def handle_query(self):\n",
        "        question = self.input.text().strip()\n",
        "        if not question:\n",
        "            return\n",
        "        self.chat_history.append(f\"You: {question}\")\n",
        "        doc = nlp(question)\n",
        "        entity = [ent.text for ent in doc.ents]\n",
        "        triplets = query_dbpedia(entity[0]) if entity else []\n",
        "        response = triplet_to_natural(triplets) if triplets else \"I couldn't find an answer.\"\n",
        "        self.chat_history.append(f\"Bot: {response}\\n\")\n",
        "        self.input.clear()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app = QApplication(sys.argv)\n",
        "    chatbot = ChatBot()\n",
        "    chatbot.show()\n",
        "    sys.exit(app.exec())\n"
      ]
    }
  ]
}